---
title: "Disbursement Projection Model"
author: "IsDB ERM Disbursement Modelling Track Team"
subtitle: Testing and Performance Evaluation
output:
  pdf_document: default
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(readxl)
library(DataExplorer)
library(patchwork)

library(gt)

theme_set(theme_minimal())

dir <- getwd()   #Updates the path to the directory where the R Code is present
input_dir <- paste0(dir, "/Inputs/") 

output_dir <- paste0(dir , "/Outputs/")

ops_data_in <- read_excel("Tests/idb_data.xlsx", 
    sheet = "ops_data")

```

# Introduction

Moody's Analytics developed a Disbursement Projection Model (DM) to project future disbursement for IsDB Projects as part of the ERM Project. The tests done on this DM and the results are captured in this document.

# Testing Methodology

The testing methodology was designed to achieve the following aims:

1.  Check if model can execute / operate as expected without any errors

2.  The ability of the model to handle different types of inputs as per specification

3.  Measure the performance of the model using standard metrics

4.  To understand and analyse the disbursement profiles produced by the model

To achieve the above aims the following tests were developed:

*-* **Analysis 1** Run the model using a sampled subset of the training data and compare the predicted values with the actual values

*-* **Analysis 2** Test the additional features of the model

*-* **Analysis 3** Run the model using synthetic data (data derived from training data using sampling), with objective to see how the model performs in the presence of new / unseen data


*-* **Analysis 4** Analysis of the disbursement profiles produced by the model

# Generation of Test inputs

## Project Types

Types of Projects used in our test sample

* **Not Signed** - Projects that have been approved but not yet signed.

* **Not Effective** - Projects approved and signed, but not yet declared as effective

* **Not Disbursing** - Projects approved, signed, and declared as effective, but yet to begin disbursing

* **Disbursing** - Projects which have been approved, signed, declared as effective, and disbursing, but not finished disbursing

# Model Testing

## Testing Plan

### Test Data Generation

When generating the test data, for each of the project types (described above) samples are produced, such that the times shown by **X** will be predicted by the model.

+----------------+--------------+-----------------+-------------------+------------------------+
| Project Type   | Time to Sig. | Time of Effect. | Time to 1st Disb. | Time 1st to Last Disb. |
+================+==============+=================+===================+========================+
| Not Signed     | X            | X               | X                 | X                      |
+----------------+--------------+-----------------+-------------------+------------------------+
| Not Effective  | \-           | X               | X                 | X                      |
+----------------+--------------+-----------------+-------------------+------------------------+
| Not Disbursing | \-           | \-              | X                 | X                      |
+----------------+--------------+-----------------+-------------------+------------------------+
| Disbursing     | \-           | \-              | \-                | X                      |
+----------------+--------------+-----------------+-------------------+------------------------+

### Types of Analysis

3 different analysis was conducted on the model using 3 separate test data sets adhering to the above test data generation methodology.

1. Comparison of values predicted by the model against actual values  
2. Testing of features of the model
3. The performance of the model in the presence of unseen / new data
4. Analysis of the disbursement profiles to understand how they are constructed


# Analysis 1 - Actual vs. Predicted Comparison

In this analysis the objective is to ascertain the predictive performance of the model, by comparing the predicted values produced by the model with actual values. For this analysis the training data set is randomly sampled and the actual milestone values are removed and saved, before the model is run to predict these milestones. The predicted values are then compared against the saved actual values, to measure the predictive performance of the model.


The test data was generated as follows:

1.  Sample Train DS - Random sampling from Training Data
2.  Create Project Types - The project types stated above are generated
3.  Milestone values are removed and saved for comparison later
4.  Merge with External DS - For external indicators
5.  Write to File - Save to CSV file in format accepted by the model

```{r datainput comp, include=FALSE}

model_input_comp <- read_csv(file = paste0(input_dir, "isdb_test_prjs_comp.csv")) %>% 
  select( -...1) %>% 
  mutate( proj_type = str_replace(project_title,  '-.*' , ''))

model_output_comp <- readRDS( file = paste0(output_dir , "model_output_comp.rda")) %>% 
  janitor::clean_names() %>% 
  mutate(
    proj_type = str_replace(project_title,  '-.*' , '')
  )

profiles_comp <- readRDS(file = paste0(output_dir , "full_disb_profile_comp.rda")) %>% 
  janitor::clean_names()

```

```{r include=FALSE}
model_input_comp_t <-
  model_input_comp %>%
  mutate(
    days_from_approval_to_signature_act = time_length(date_of_signature_act - date_of_approval , "days"),
    days_from_signature_to_effectiveness_act = time_length(date_of_effective_act - date_of_signature_act, "days"),
    days_from_effectiveness_to_first_disbursement_act  = time_length(date_of_first_disb_act - date_of_effective_act,   "days"),
    days_from_first_to_final_disbursement_act = time_length(date_of_last_disb_act - date_of_first_disb_act,   "days")
  ) %>% 
  select(project_id , contains("act") )
```

```{r join with projected, include=FALSE}
comp1 <- 
  model_output_comp %>% 
  inner_join(model_input_comp_t , by = "project_id" ) %>% 
  mutate(
    days_from_approval_to_signature_res = days_from_approval_to_signature_act - days_from_approval_to_signature,
    days_from_signature_to_effectiveness_res = days_from_signature_to_effectiveness_act - days_from_signature_to_effectiveness,
    days_from_effectiveness_to_first_disbursement_res = days_from_effectiveness_to_first_disbursement_act -
      days_from_effectiveness_to_first_disbursement,
    days_from_first_to_final_disbursement_res = days_from_first_to_final_disbursement_act - days_from_first_to_final_disbursement
    ) %>% 
  rename( date_of_effectiveness_act = date_of_effective_act,
          date_of_first_disbursement_act = date_of_first_disb_act,
          date_of_final_disbursement_act = date_of_last_disb_act )
```

```{r echo=FALSE}
plot_act_pred <- function(milestone , data) {
  
  
  act <- paste0( "days_from_" , milestone , "_act" )
  
  pred <- paste0( "days_from_" , milestone )
  
  ptitle <- paste0( str_to_title( str_replace_all( milestone , "_" , " " ) ) )
  
  # ptype <- switch( str_remove( deparse(substitute(comp_sig)) , "comp_") , 
  #                  "sig" = "Not Signed" ,
  #                  "eff" = "Not Effective",
  #                  "fstd" = "Not Disbursing",
  #                  "lstd" = "Disbursing")
  # 
  # psubtitle <- paste0(ptype ,  " Projects") 
  
  p <- data %>% 
  ggplot( aes(x = !!sym(act) , y = !!sym(pred)) ) +
  geom_point() + 
  geom_abline(slope = 1 , intercept = 0) +
  geom_smooth(method = "lm" , formula = y ~ x + 0) +
  expand_limits(x = 0, y = 0) +
    labs(title = ptitle ,  x = "Actual" , y = "Predicted")
  
  return(p) 
}

std_res <- function(res) {
  return(
        res / sqrt( sum( res^2 ) / ( length(res) - 2 )   )
  )
}

comp_sig <-  comp1 %>% 
  filter( str_detect(project_id , "NS")) %>% 
  mutate(
    days_from_approval_to_signature_std_res = std_res(days_from_approval_to_signature_res)
    )                                                      

comp_eff <- comp1 %>% 
  filter( str_detect(project_id , "NE")) %>% 
  mutate(
    days_from_signature_to_effectiveness_std_res = std_res(days_from_signature_to_effectiveness_res)
       )                                

comp_fstd <- comp1 %>% 
  filter( str_detect(project_id , "ND"))  %>% 
  mutate(
    days_from_effectiveness_to_first_disbursement_std_res = std_res(days_from_effectiveness_to_first_disbursement_res)
       )                                

comp_lstd <- comp1 %>% 
  filter( str_detect(project_id , "CD"))  %>% 
  mutate(
      days_from_first_to_final_disbursement_std_res = std_res(days_from_first_to_final_disbursement_res)
       )                                

c1 <- c( "approval_to_signature" , "signature_to_effectiveness" , "effectiveness_to_first_disbursement" ,
         "first_to_final_disbursement")
```

```{r echo=FALSE}
plot_res <- function(milestone , data) {
  fit <- paste0( "days_from_" , milestone  )
  
  res <- paste0( "days_from_" , milestone , "_res" )
  
  std_res <- paste0( "days_from_" , milestone , "_std_res" )
  
  ptitle <- paste0( str_to_title( str_replace_all( milestone , "_" , " " ) ) )
  
  p <- data %>%
  mutate( sd2 = ( abs( !!sym(std_res) ) > 2) ) %>% 
  ggplot( aes(x = !!sym(fit) , y = !!sym(res)) ) +
  geom_point(aes( color =  sd2 )) + 
  scale_color_manual(values=c("#458B74" , "#B22222"))+
  geom_abline(slope = 0 , intercept = 0 ,linetype = "dashed") +
  geom_smooth(  color = "#458B00" ) +
  #  expand_limits(x = 0, y = 0) +
    labs(title = "Linearity", 
         #subtitle = 'Reference Line should be flat and horizontal',
         x = "Predicted Value" , y = "Residuals") +
    theme(legend.position='none',
          plot.caption = element_text(color = "#B22222", face = "italic"))
  
  return(p) 
}

plot_std_res <- function(milestone , data) {
  fit <- paste0( "days_from_" , milestone  )
  
  res <- paste0( "days_from_" , milestone , "_std_res" )
  
  ptitle <- paste0( str_to_title( str_replace_all( milestone , "_" , " " ) ) )
  
  p <- data %>% 
  mutate( sd2 = ( abs( !!sym(res) ) > 2) ) %>% 
  ggplot( aes(x = !!sym(fit) , y = sqrt( abs(!!sym(res))  )) ) +
  geom_point(aes( color =  sd2 )) + 
  scale_color_manual(values=c("#458B74" , "#B22222")) +
   geom_smooth( method = "loess" , color = "#458B00" ) +
   # expand_limits(x = 0, y = 0) +
    labs(title = 'Homogeneity of Variance' ,  
         #subtitle = 'Reference Line should be flat and horizontal',
         x = "Predicted Value" , 
         y = expression(sqrt("Std. Residuals")) , caption = "RED = Outliers") +
    theme(legend.position='none',
          plot.caption = element_text(color = "#B22222", face = "italic"))
  
  return(p) 
}

plot_res_hist <- function(milestone , data) {
  res <- paste0( "days_from_" , milestone , "_res" )
  
  ptitle <- paste0( str_to_title( str_replace_all( milestone , "_" , " " ) ) )
  p <- data %>%
    ggplot( aes(x = !!sym(res) ) ) +
    geom_histogram(aes(y=..density.. ) , bins = 30 , alpha = .5) +
    geom_density() +
    scale_x_continuous() +
    labs(title = ptitle ,  
         x = "Residual Values" )
  
  return(p)
}

plot_res_qq <- function(milestone , data) {
  res <- paste0( "days_from_" , milestone , "_res" )
  
  ptitle <- paste0( str_to_title( str_replace_all( milestone , "_" , " " ) ) )
  p <- data %>%
    mutate( sd2 = ( abs( !!sym(res) ) > 2) ) %>%
    ggplot( aes(sample = !!sym(res) ) ) +
    stat_qq() +
    stat_qq_line() +
    labs(title = ptitle ,  
         y = "Sample" ,
         x = "Theoratical")
  
  return(p)
}

```

### Not Signed Projects

Analysis of the Predicted times compared to actual.

```{r plots, echo=FALSE}
#plot_act_pred( comp_sig , "approval_to_signature"  )
wrap_plots( map(c1, plot_act_pred , comp_sig) ) + 
  plot_annotation(
  title = 'Not Signed Projects',
  subtitle = 'Predicted vs. Actual (months)',
  caption = paste0('Based on a sample input of ' , nrow(comp_sig) , ' projects')
)
```

### Analysis of Residuals

The Residual is defined as $Residual = R_i = (Y_{act} - Y_{est})$ where $Y$ is the output or predicted variable

The Standardized Residual is defined as 

$$S_{i} = \frac{R_i}{\sqrt{\frac{\sum (Y_{act} - Y_{est})^2}{n - 2}}} = \frac{Residual_i}{Standard~Deviation~of~Residual_i} $$

```{r echo=FALSE, message=FALSE, warning=FALSE}
p1 <- plot_res(c1[1] , comp_sig) 

p2 <- plot_std_res(c1[1] , comp_sig) 

(p1 | p2) + 
  plot_annotation(
  title = 'Not Signed Projects',
  subtitle = 'Approval to Signature times',
  #caption = paste0('Based on a sample input of ' , nrow(comp_sig) , ' projects')
  caption = 'Reference Line should be flat and horizontal'
  )

```


```{r echo=FALSE}
p1 <- plot_res_hist(c1[1] , comp_sig)

p2 <- plot_res_qq(c1[1] , comp_sig)

(p1 | p2) + 
  plot_annotation(
  title = 'Not Signed Projects',
  subtitle = "Distribution of Residuals",
  caption = paste0('Based on a sample input of ' , nrow(comp_sig) , ' projects')
  )
```

### Outlier value detection

Values where $S_{res} > 2$ are considered as Outliers

```{r echo=FALSE}
outlier_tbl <- function(var , start_var , end_var ,  data) {
  
  varname = paste0( "days_from_" , var)
  
  #start_var = paste0( "date_of_" , str_remove(var , "_.+") )
  
  #end_var = paste0( "date_of_" , str_remove(var , "^.+_") )
  
  data %>% filter( abs( !!sym(paste0( varname , "_std_res") ) )> 2) %>%
  select(
    project_id ,
    !!sym( start_var ),
    actual = !!sym( paste0( end_var , "_act")  ),
    predicted = !!sym( end_var ),
    actual_days = !!sym(paste0( varname , "_act")),
    predicted_days = !!sym(varname),
    residual = !!sym(paste0( varname , "_res"))
  ) %>% 
    arrange(residual) %>% 
  gt() 
}


c2 <- c( "date_of_approval" , "date_of_signature" ,  "date_of_effectiveness" , "date_of_first_disbursement" , "date_of_final_disbursement")

outlier_tbl( c1[1] , c2[1] , c2[2] , comp_sig) %>% 
    tab_header(
    title = "Model Outliers - Not Signed Projects",
    subtitle = "Date of Signature"
  )

```



```{r echo=FALSE}
comp_sig %>% 
  yardstick::metrics(days_from_approval_to_signature_act, days_from_approval_to_signature ) %>%  select(-2) %>%
  mutate( .metric = str_to_upper(.metric)) %>% 
  gt() %>%  
fmt_number(columns = 2) %>%  tab_header(
    title = "Not Signed Projects",
    subtitle = "Model Performance Measurements"
  ) %>% 
  tab_footnote(
    footnote = "Accuracy of predicted Date of Signature vs. Actual",
    locations = cells_column_labels(
      columns = 2
    ))  %>% 
  tab_footnote(
    footnote = "RMSE - Root Mean Square Error (lower better)",
    locations = cells_body(
      columns = 1 , row  = 1
    ))  %>% 
  tab_footnote(
    footnote = "RSQ - R Squared (higher better)",
    locations = cells_body(
      columns = 1 , row  = 2
    ))  %>% 
  tab_footnote(
    footnote = "MAE - Mean Absolute Error (lower better)",
    locations = cells_body(
      columns = 1 , row  = 3
    ))  
```


### Conclussions

* The Approval to Signature Model has a $R^2$ of 0.2

* The presence of large outliers ($ > 2 SD$) impacts model performance

* External factors (not considered here) affect the time from approval to signature


### Not Effective Projects

Analysis of the Predicted effectiveness times compared to actual.

```{r, echo=FALSE}
wrap_plots( map(c1[2:4], plot_act_pred , comp_eff) , ncol = 2 ) + 
  plot_annotation(
  title = 'Not Effective Projects',
  subtitle = 'Predicted vs. Actual (days)',
  caption = paste0('Based on a sample input of ' , nrow(comp_eff) , ' projects')
)
```

Analysis of Residuals

```{r echo=FALSE,  message=FALSE, warning=FALSE}
p1 <- plot_res(c1[2] , comp_eff) 

p2 <- plot_std_res(c1[2] , comp_eff) 

(p1 | p2) + 
  plot_annotation(
  title = 'Not Effective Projects',
  caption = paste0('Based on a sample input of ' , nrow(comp_eff) , ' projects')
  )
```

Outliers

```{r echo=FALSE}
outlier_tbl( c1[2] ,  c2[2] , c2[3] , comp_eff) %>% 
    tab_header(
    title = "Model Outliers - Not Effective Projects",
    subtitle = "Date of Effectiveness"
  )
```


```{r echo=FALSE}
comp_eff %>% 
  yardstick::metrics(days_from_signature_to_effectiveness_act, days_from_signature_to_effectiveness ) %>%  select(-2) %>%
  mutate( .metric = str_to_upper(.metric)) %>% 
  gt() %>%  
fmt_number(columns = 2) %>%  tab_header(
    title = "Not Effective Projects",
    subtitle = "Model Performance Measurements"
  ) %>% 
  tab_footnote(
    footnote = "Accuracy of predicted Date of Effectiveness vs. Actual",
    locations = cells_column_labels(
      columns = 2
    ))  %>% 
  tab_footnote(
    footnote = "RMSE - Root Mean Square Error (lower better)",
    locations = cells_body(
      columns = 1 , row  = 1
    ))  %>% 
  tab_footnote(
    footnote = "RSQ - R Squared (higher better)",
    locations = cells_body(
      columns = 1 , row  = 2
    ))  %>% 
  tab_footnote(
    footnote = "MAE - Mean Absolute Error (lower better)",
    locations = cells_body(
      columns = 1 , row  = 3
    ))  
```



### Conclussions

* The Signature to Effectiveness Model has a $R^2$ of 0.1

* The presence of large outliers ($ > 2 SD$) impacts model performance

* External factors (not considered here) affect the time from signature to effectiveness

## Not Disbursing Projects

Analysis of the Predicted 1st Disbursement times compared to actual.

```{r, echo=FALSE}
wrap_plots( map(c1[3:4], plot_act_pred , comp_fstd) , ncol = 2 ) + 
  plot_annotation(
  title = 'Not Disbursing Projects',
  subtitle = 'Predicted vs. Actual (days)',
  caption = paste0('Based on a sample input of ' , nrow(comp_sig) , ' projects')
)
```

Analysis of Residuals

```{r echo=FALSE, message=FALSE,}
p1 <- plot_res(c1[3] , comp_fstd) 

p2 <- plot_std_res(c1[3] , comp_fstd) 

(p1 | p2) + 
  plot_annotation(
  title = 'Not Disbursing Projects',
  caption = paste0('Based on a sample input of ' , nrow(comp_sig) , ' projects')
  )

```

Outliers

```{r echo=FALSE}
outlier_tbl( c1[3] ,  c2[3] , c2[4] , comp_fstd) %>% 
    tab_header(
    title = "Model Outliers - Not Disbursing Projects",
    subtitle = "Date of 1st Disb."
  )
```


```{r echo=FALSE}
comp_fstd %>% 
  yardstick::metrics(days_from_effectiveness_to_first_disbursement_act, days_from_effectiveness_to_first_disbursement ) %>%  select(-2) %>%
  mutate( .metric = str_to_upper(.metric)) %>% 
  gt() %>%  
fmt_number(columns = 2) %>%  tab_header(
    title = "Not Disbursing Projects",
    subtitle = "Model Performance Measurements"
  ) %>% 
  tab_footnote(
    footnote = "Accuracy of predicted Date of 1st Disb. vs. Actual",
    locations = cells_column_labels(
      columns = 2
    ))  %>% 
  tab_footnote(
    footnote = "RMSE - Root Mean Square Error (lower better)",
    locations = cells_body(
      columns = 1 , row  = 1
    ))  %>% 
  tab_footnote(
    footnote = "RSQ - R Squared (higher better)",
    locations = cells_body(
      columns = 1 , row  = 2
    ))  %>% 
  tab_footnote(
    footnote = "MAE - Mean Absolute Error (lower better)",
    locations = cells_body(
      columns = 1 , row  = 3
    ))  
```

### Conclussions

* The Effectiveness to First Disbursement Model has a $R^2$ of 0.03, which signifies that the model is unable to account for a majority of the variation in the output

* The presence of large outliers ($ > 2 SD$) impacts model performance

* External factors (not considered here) affect the time from effectiveness to first disbursements

### Disbursing Projects

Analysis of the Predicted 1st to last Disbursement times compared to actual.

```{r, echo=FALSE}
wrap_plots( map(c1[4], plot_act_pred , comp_fstd)  ) + 
  plot_annotation(
  title = 'Disbursing Projects',
  subtitle = 'Predicted vs. Actual (days)',
  caption = paste0('Based on a sample input of ' , nrow(comp_sig) , ' projects')
)
```

Analysis of Residuals

```{r echo=FALSE,  message=FALSE, warning=FALSE}
p1 <- plot_res(c1[4] , comp_lstd) 

p2 <- plot_std_res(c1[4] , comp_lstd) 

(p1 | p2) + 
  plot_annotation(
  title = 'Disbursing Projects',
  caption = paste0('Based on a sample input of ' , nrow(comp_sig) , ' projects')
  )
```

Outliers

```{r echo=FALSE}
outlier_tbl( c1[4] ,  c2[4] , c2[5] , comp_lstd) %>% 
    tab_header(
    title = "Model Outliers - Not Disbursing Projects",
    subtitle = "Date of Final Disb."
  )
```

```{r echo=FALSE}
comp_lstd %>% 
  yardstick::metrics(days_from_first_to_final_disbursement_act, days_from_first_to_final_disbursement ) %>%  select(-2) %>%
  mutate( .metric = str_to_upper(.metric)) %>% 
  gt() %>%  
fmt_number(columns = 2) %>%  tab_header(
    title = "Disbursing Projects",
    subtitle = "Model Performance Measurements"
  ) %>% 
  tab_footnote(
    footnote = "Accuracy of predicted Date of final Disb. vs. Actual",
    locations = cells_column_labels(
      columns = 2
    ))  %>% 
  tab_footnote(
    footnote = "RMSE - Root Mean Square Error (lower better)",
    locations = cells_body(
      columns = 1 , row  = 1
    ))  %>% 
  tab_footnote(
    footnote = "RSQ - R Squared (higher better)",
    locations = cells_body(
      columns = 1 , row  = 2
    ))  %>% 
  tab_footnote(
    footnote = "MAE - Mean Absolute Error (lower better)",
    locations = cells_body(
      columns = 1 , row  = 3
    ))  
```


### Conclussions

* The First to Final Disbursement Model has a $R^2$ of 0.39

* The presence of large outliers ($ > 2 SD$) impacts model performance

* External factors (not considered here) affect the time from first to final disbursement


# Analysis 2 - Testing of Model Features

In this analysis the features of the model which provide for the setting of the limits (Cap) and Override on the project milestones is checked. The objective being, to check if these features of the model work as per expectation.

The test data was generated as follows:

1.  Sample Train DS - Random sampling from Training Data
2.  Create Project Types - The project types stated above are generated
3.  Milestone Cap is set by random sampling of possible caps (i.e. 3 months, 6 months, 9 months)
4.  Milestone Override is set by using the actual date of the milestone from the Train DS
4.  Merge with External DS - For external indicators
5.  Write to File - Save to CSV file in format accepted by the model

```{r datainput check, include=FALSE}

model_input_check <- read_csv(file = paste0(input_dir, "isdb_test_prjs_check.csv")) %>% 
  select( -...1) 

model_output_check <- readRDS( file = paste0(output_dir , "model_output_check.rda")) %>% 
  janitor::clean_names() 

model_output_check <- model_output_check %>% 
  inner_join( model_input_check %>%  select(where( is.character ) , -project_title, -project_title_org , -profile ) , by = c("project_id"))


profiles_check <- readRDS(file = paste0(output_dir , "full_disb_profile_check.rda")) %>% 
  janitor::clean_names()

```

## Checks

### Milestone Limits

A series of tests were done to check the effectiveness of applying limits (Cap) on the Project milestones.

```{r echo=FALSE}

check_cap <- function( ctype , mtype ) {
  
  days_cap <- paste0( "days_from_" , mtype , "_cap" )
  days_pred <- paste0( "days_from_" , mtype )
  
  model_output_check %>%
  filter( check_type == ctype ) %>% 
  select( check_type , project_id , sym(days_cap) , sym(days_pred) ) %>% 
  mutate(
      check_cap = !!sym(days_cap) >= !!sym(days_pred) 
   ) %>% 
  group_by(check_type) %>% 
    summarise( no_of_tests = n()  , no_pass = sum(check_cap) ) %>% 
    mutate( test_status = if_else( no_of_tests == no_pass , "PASS" , "FAIL")
      )
  
}


ctypes <- c("NSCAP" , "NECAP" , "NDCAP")

#check_ptype( "NDCAP" , c1[3]  )
map2_dfr( ctypes , c1[1:3]  , check_cap) %>% 
  mutate( check_type = 
            case_when( check_type == "NSCAP" ~ "Not Signed Cap",
                       check_type == "NECAP" ~ "Not Effective Cap",
                       T ~ "Not Disbursing Cap")) %>% 
  gt() %>% 
  tab_header(title = "Check of applying limits (Cap) on Project Milestones")

```

As shown above all of the tests performed have passed.

### Milestone Override

A series of tests were done to check the effectiveness of applying overrides on the Project milestones.

```{r echo=FALSE}

t <- model_output_check %>%  
  filter( check_type == "NSOVR") %>% 
  select( project_id , date_of_signature_override , date_of_signature ) %>% 
  mutate(
    check_ovr_signature = date_of_signature_override == date_of_signature
  )
      

check_ovr <- function( ctype , mtype ) {
  
  days_ovr <- paste0( "date_of_" , mtype , "_override" )
  days_pred <- paste0( "date_of_" , mtype )
  
  model_output_check %>%
  filter( check_type == ctype ) %>% 
  select( check_type , project_id , sym(days_ovr) , sym(days_pred) ) %>% 
  mutate(
      check_ovr = !!sym(days_ovr) == !!sym(days_pred) 
   ) %>% 
  group_by(check_type) %>% 
    summarise( no_of_tests = n()  , no_pass = sum(check_ovr) ) %>% 
    mutate( test_status = if_else( no_of_tests == no_pass , "PASS" , "FAIL")
      )
  
} 


cm <- c ("signature" , "effectiveness" , "first_disbursement" , "final_disbursement" )

ctypes <- c( "NSOVR" , "NEOVR" , "NDOVR" , "CDOVR" )


#check_ovr( ctypes[1] , cm[1] )

map2_dfr( ctypes , cm  , check_ovr) %>% 
  mutate( check_type = 
            case_when( check_type == "NSOVR" ~ "Not Signed Override",
                       check_type == "NEOVR" ~ "Not Effective Override",
                       check_type == "NDOVR" ~ "Not Disbursing Override",
                       T ~ "Disbursing Override")) %>% 
  gt() %>% 
  tab_header(title = "Check of applying overrides on Project Milestones")

```

As shown above all of the tests performed have passed.


# Analysis 3 - Testing with Synthetic Data

The simulated data was generated as follows:

1.  Sample Train DS - Random sampling from Training Data
2.  Create Project Types - The project types stated above are generated
3.  Randomize Fields - Key fields i.e. Sector, Profile are randomized, and also the milestone dates
4.  Merge with External DS - For external indicators
5.  Write to File - Save to CSV file in format accepted by the model

```{r eval=FALSE, include=FALSE}

library(DiagrammeR)

grViz("digraph test{
  graph [layout = dot, rankdir = LR]
  
  node [shape = rectangle]        
  rec1 [label = 'Step 1. Sample Train DS']
  rec2 [label = 'Step 2. Create Project Types']
  rec3 [label =  'Step 3. Randomize Fields']
  rec4 [label = 'Step 4. Merge with External DS']
  rec5 [label = 'Step 5. Write to File']
  
  
  # edge definitions with the node IDs
  rec1 -> rec2 -> rec3 -> rec4 -> rec5
  }")

```

```{r datainput sim, include=FALSE}

model_input_sim <- read_csv(file = paste0(input_dir, "isdb_test_prjs_sim.csv")) %>% 
  select( -...1) %>% 
  mutate( proj_type = str_replace(project_title,  '-.*' , ''))

model_output_sim <- readRDS( file = paste0(output_dir , "model_output_sim.rda")) %>% 
  janitor::clean_names() %>% 
  mutate(
    proj_type = str_replace(project_title,  '-.*' , '')
  )

model_output_sim <- model_output_sim %>% 
  inner_join( model_input_sim %>%  select(where( is.character ) , -proj_type , -project_title, -project_title_org  ) , by = c("project_id"))


profiles_sim <- readRDS(file = paste0(output_dir , "full_disb_profile_sim.rda")) %>% 
  janitor::clean_names()

```

## Output Data Summary

```{r echo=FALSE}
introduce(model_output_sim) %>% 
  pivot_longer(1:9) %>% 
  gt()


model_output_sim %>%  
  count(proj_type) %>% 
  gt() %>% 
  tab_header(
    title = "Model Output by Project Type"
  )

```

## Distribution - Input data

```{r eval=FALSE, include=FALSE}
plot_dcvar <- function(var) {
  
  model_input_sim %>% 
  group_by( proj_type ) %>% 
  count( !!sym(var) , sort = T) %>% 
  mutate( dc_var = tidytext::reorder_within( !!sym(var) ,  n , proj_type)) %>% 
  ggplot(aes( dc_var , n)) +
  geom_col(aes(fill=proj_type), show.legend = FALSE) +
  coord_flip() +
  tidytext::scale_x_reordered() +
  facet_wrap(~proj_type, scales = "free_y") 
  
}

l <- c( "sector" , "sub_mode_of_finance" ,  "income_classification")

map(l , plot_dcvar)



```

## Check Model Output

```{r echo=FALSE}

apr_amt <- model_input_sim %>%  
   summarise( total_apr_amt = sum(approval_amount_usd)/1e6  ) 

disb_amt <- profiles_sim %>%  summarise( total_disb = sum( amount_disbursed_between_tenors ) /1e6 )

tibble( 
  apr_amt,
  disb_amt 
  ) %>% 
  mutate(
    match = (  round(apr_amt) == round(disb_amt) )
  ) %>% 
  gt() %>% 
  fmt_number(columns = 1:2) %>% 
  tab_footnote(
    footnote = "Total value of approved amounts from Test data set (input)",
    locations = cells_column_labels(
      columns = 1
    )
  ) %>% 
  tab_footnote(
    footnote = "Total value of disbursed amounts from disbursement profiles generated from the model",
    locations = cells_column_labels(
      columns = 2
    )
  ) %>% 
  tab_header(
    title = "Model Input / Output Reconciliation"
  )
```


The 2 model outputs **do not match**, further investigation is needed.



```{r echo=FALSE}

apr_amts <- model_input_sim %>%  
  select( project_id , proj_type, approval_amount_usd ) %>% 
  mutate( total_apr = (approval_amount_usd)/1e6 )
  # summarise( total_apr_amt = sum(approval_amount_usd)/1e6  ) 

disb_amts <- profiles_sim %>% 
  group_by( project_id) %>% 
  summarise( total_disb = sum( amount_disbursed_between_tenors ) /1e6 )

t <- apr_amts %>% 
  left_join(disb_amts)

t %>%  filter( is.na( total_disb ) )

tibble( 
  apr_amt,
  disb_amt 
  ) %>% 
  mutate(
    match = (  round(apr_amt) == round(disb_amt) )
  ) %>% 
  gt() %>% 
  fmt_number(columns = 1:2) %>% 
  tab_footnote(
    footnote = "Total value of approved amounts from Test data set (input)",
    locations = cells_column_labels(
      columns = 1
    )
  ) %>% 
  tab_footnote(
    footnote = "Total value of disbursed amounts from disbursement profiles generated from the model",
    locations = cells_column_labels(
      columns = 2
    )
  ) %>% 
  tab_header(
    title = "Model Input / Output Reconciliation"
  )
```


## Distribution of Times - Output Data

The output of the model is analysed to better understand the spread of values produced by the model. The Analysis is done by project type, the dates predicted by the model for each project type.

```{r eval=FALSE, include=FALSE}
t <- model_output_sim %>% 
  select(proj_type , days_from_approval_to_signature , days_from_signature_to_effectiveness,
         days_from_effectiveness_to_first_disbursement , days_from_first_to_final_disbursement)

plot_boxplot(t, by = "proj_type" , ncol = 2)

```

```{r get_each, echo=FALSE}
get_each <- function(x ,data){
  data %>% 
    summarise(
    across( (starts_with("days_from") & contains(x) & !contains("_cap")) , 
            list(mean = mean , sd = sd , min = min , max = max , median = median),  
            .names = "{.fn}" ) ,
  ) %>% 
    mutate(measure = x) %>% 
    relocate(measure)
  
}

l2 <- c("approval_to_signature" , "signature_to_effectiveness" , "effectiveness_to_first" ,"first_to_final" )


```

```{r plot_hist, include=FALSE}
plot_hist <- function(data_src , var){
  
  mean_val = mean(var)
  
  #medean_val = median(var)
  
  var_name = str_remove( deparse(substitute(var)) , ".*\\$days_from_" )
  
  #geom_histogram(aes(y=..density.. , fill = ), fill="lightblue")+

  
  data_src %>% 
  ggplot(aes(var)) +
  #geom_histogram(aes(y=..density.. , fill = catch_up_shift ) )+
  geom_histogram(aes(y=..density.. ) , bins = 30 , alpha = .5)+
  #geom_density(alpha=.2, fill="#FF6666") +
  geom_density(alpha=.2) + 
  geom_vline(aes(xintercept= mean_val),
            color="black", linetype="dashed", size=.5 , alpha = .5) +
  # geom_vline(aes(xintercept= medean_val),
  #           color="blue", linetype="dashed", size=.5 , alpha = .5) +
  annotate("text" , x = mean_val , y  = 0 , label = paste0(sprintf("Avg. %.2f",mean_val)) , color = "red") +
  labs(title = var_name)
  
}
```

## Not Signed Projects

```{r echo=FALSE}

data_in <- model_output_sim %>% 
  filter(proj_type == "Not Signed" )

map_dfr(l2, get_each , data_in ) %>% 
  gt() %>% 
    fmt_number(columns = 2:6) %>% 
  tab_header(
    title = "Projection - Not Signed Projects",
    subtitle = "Model Output Milestone Time Analysis"
  )




p1 <- plot_hist(data_in , data_in$days_from_approval_to_signature)
  
  
p2 <- plot_hist(data_in , data_in$days_from_signature_to_effectiveness)


p3 <- plot_hist(data_in , data_in$days_from_effectiveness_to_first_disbursement)
  
  
p4 <- plot_hist(data_in , data_in$days_from_first_to_final_disbursement)
  
 

(p1 | p2) / (p3 | p4) + plot_annotation(
  title = 'Model Output - Projects Not Signed',
  subtitle = 'Distribution of projected time-taken by milestones(months)',
  caption = paste0('Based on a sample input of ' , nrow(data_in) , ' Approved but not Signed projects')
)


#t <- map(l4 , plot_dist2 , model_output_sim %>% filter(proj_type == "Not Signed" ) )

#map( 1:4 , ~wrap_plots(t[[.x]]) )

```

## Not Effective Projects

```{r echo=FALSE}

data_in <- model_output_sim %>% 
  filter(proj_type == "Not Effective" )

map_dfr(l2[2:4], get_each , data_in) %>% 
  gt() %>% 
    fmt_number(columns = 2:6) %>% 
  tab_header(
    title = "Projection - Not Effective Projects",
    subtitle = "Model Output Milestone Time Analysis"
  )

p1 <- plot_hist(data_in , data_in$days_from_signature_to_effectiveness)


p2 <- plot_hist(data_in , data_in$days_from_effectiveness_to_first_disbursement)
  
  
p3 <- plot_hist(data_in , data_in$days_from_first_to_final_disbursement)
  
 

(p1 | p2) / (p3 ) + plot_annotation(
  title = 'Model Output - Projects Not Signed',
  subtitle = 'Distribution of projected time-taken by milestones(months)',
  caption = paste0('Based on a sample input of ' , nrow(data_in) , ' Approved but not Signed projects')
)


#t <- map(l4 , plot_dist2 , model_output_sim %>% filter(proj_type == "Not Signed" ) )

#map( 1:4 , ~wrap_plots(t[[.x]]) )

# t <- map(l4[2:4] , plot_dist2 , model_output_sim %>% filter(proj_type == "Not Effective") )
# 
# 
# map( 1:3 , ~wrap_plots(t[[.x]] , ncol = 2) )

```

## Not Disbursing Projects

```{r echo=FALSE}
data_in <- model_output_sim %>% 
  filter(proj_type == "Not Disbursing" )

map_dfr(l2[3:4], get_each , data_in) %>% 
  gt() %>% 
    fmt_number(columns = 2:6) %>% 
  tab_header(
    title = "Projection - Not Disbursing Projects",
    subtitle = "Model Output Milestone Time Analysis"
  )

p1 <- plot_hist(data_in , data_in$days_from_effectiveness_to_first_disbursement)
  
  
p2 <- plot_hist(data_in , data_in$days_from_first_to_final_disbursement)
  
 

(p1 | p2)  + plot_annotation(
  title = 'Model Output - Projects Not Disbursing',
  subtitle = 'Distribution of projected time-taken by milestones(months)',
  caption = paste0('Based on a sample input of ' , nrow(data_in) , ' Approved but not Signed projects')
)

# t <- map(l4[3:4] , plot_dist2 , model_output_sim %>% filter(proj_type == "Not Disbursing") )
# 
# 
# map( 1:2 , ~wrap_plots(t[[.x]] , ncol = 2) )


```

## Disbursing Projects

```{r echo=FALSE}
data_in <- model_output_sim %>% 
  filter(proj_type == "Disbursing" )

map_dfr(l2[4], get_each , data_in) %>% 
  gt() %>% 
    fmt_number(columns = 2:6) %>% 
  tab_header(
    title = "Projection - Disbursing Projects",
    subtitle = "Model Output Milestone Time Analysis"
  )

p1 <- plot_hist(data_in , data_in$days_from_first_to_final_disbursement)
  
 

p1  + plot_annotation(
  title = 'Model Output - Disbursing Projects',
  subtitle = 'Distribution of projected time-taken by milestones(months)',
  caption = paste0('Based on a sample input of ' , nrow(data_in) , ' Approved but not Signed projects')
)

# t <- map(l4[4] , plot_dist2 , model_output_sim %>% filter(proj_type == "Disbursing") )
# 
# 
# map( 1 , ~wrap_plots(t[[.x]] , ncol = 2) )


```

<!-- ## Distribution of Times - Output Data -->

```{r eval=FALSE, include=FALSE}
t <- model_output_sim %>% 
  select(proj_type , days_from_approval_to_signature , days_from_signature_to_effectiveness,
         days_from_effectiveness_to_first_disbursement , days_from_first_to_final_disbursement)

plot_boxplot(t, by = "proj_type" , ncol = 2)

```

```{r eval=FALSE, include=FALSE}
get_each <- function(x ,data){
  data %>% 
    summarise(
    across( (starts_with("days_from") & contains(x) & !contains("_cap")) , 
            list(mean = mean , sd = sd , min = min , max = max , median = median),  
            .names = "{.fn}" ) ,
  ) %>% 
    mutate(measure = x) %>% 
    relocate(measure)
  
}

l2 <- c("approval_to_signature" , "signature_to_effectiveness" , "effectiveness_to_first" ,"first_to_final" )


map_dfr(l2, get_each , model_output_sim %>% filter( proj_type == "Not Signed")) %>% 
  gt() %>% 
    fmt_number(columns = 2:6) %>% 
  tab_header(
    title = "Projection - Not Signed Projects",
    subtitle = "Model Output Milestone Time Analysis"
  )


map_dfr(l2, get_each , ops_data %>% filter( proj_type != "Not Signed",
                                            proj_type != "Not Effective")) %>% 
  gt() %>% 
    fmt_number(columns = 2:6) %>% 
  tab_header(
    title = "Training Data Set",
    subtitle = "Milestone Time Analysis"
  )


get_each(l2[1] , ops_data %>% filter( proj_type_code > 1 ) ) %>% 
  bind_rows(get_each(l2[2] , ops_data %>% filter( proj_type_code > 2 ))) %>% 
  bind_rows(get_each(l2[3] , ops_data %>% filter( proj_type_code > 3 ))) %>% 
  bind_rows(get_each(l2[4] , ops_data %>% filter( proj_type_code > 4 )) ) %>% 
  gt() %>% 
    fmt_number(columns = 2:6) %>% 
  tab_header(
    title = "Training Data Set",
    subtitle = "Milestone Time Analysis"
  )


```

# Analysis 4 - Disbursement Profiles

The model generates disbursement profiles, based on the time lapsed (from first to final disbursement) and the cumulative percentage disbursed. For the different project types in the test date we analyse the disbursement profiles produced.

```{r echo=FALSE, message=FALSE, warning=FALSE}
plot_profile <- function(mtype) {
  

  
  profiles_sim %>%  
  mutate( ptype = str_sub( project_id , 1, 2)) %>%
    filter(ptype == mtype) %>% 
  ggplot(aes(x = standard_tenor , y  = percentage_disbursed , group = project_id) ) +
  geom_line( color = "gray" , alpha = 0.5) +
  geom_smooth( mapping = aes(x = standard_tenor , y  = percentage_disbursed ) , inherit.aes = F , method = "loess"  ) +
  geom_abline(slope = 100 , intercept = 0 , linetype = "dashed" , color = "black" )

}


p1 <- plot_profile( "NS") +
  labs(title = "Not Signed")

p2 <- plot_profile( "NE") +
  labs(title = "Not Effective")

( p1 | p2) + plot_annotation(
  title = 'Disbursement Profiles',
  subtitle = 'Based on Project Type',
  caption = "Gray - Predicted Profile, Blue - Smoothened Profile , Black - Linear ref. line"
  )

p3 <- plot_profile( "ND") +
  labs(title = "Not Disbursing")

p4 <- plot_profile( "CD") +
  labs(title = "Disbursing")

( p3 | p4) + plot_annotation(
  title = 'Disbursement Profiles',
  subtitle = 'Based on Project Type',
  caption = "Gray - Predicted Profile, Blue - Smoothened Profile , Black - Linear ref. line"
  )

```

* The disbursement profiles for Not Signed, Not Effective and Not Disbursing Projects are very similar and are almost linear

* The disbursement profile for the Disbursing projects, is less linear as the amount already disbursed determines the starting point of the cumulative disbursement percentage

* All projects are assumed to disburse to 100% in the model, but in real life scenarios project may disburse less than 100% of their approved amount

# Conclussions and for further discussions

* The model produces outputs which have a normal distribution (centered around mean)

* The distributions have a long tail, i.e. the model produces some high values

* The application of limits (Caps) and overrides on project milestones, performs as expected

* There are issues with the reconciliation of the model output which need to be resolved (already raised)

* While the model operated as expected, it was felt the R-code could be made more robust, to be able to better handle errors and unexpected inputs

* There is a need to verify the model against the original specification as set-out in the Business Analysis document

* While in the testing, the standalone performance of the model was evaluated, it is necessary evaluate the model in conjunction with other ERM models which depend upon it, in order to fully ascertain its performance

* Certain downstream models which will depend on the disbursement projections, require the  disbursement profiles to operate on, will it be possible to produce these from the model ?

* Can the model summary output be transformed, to provide the likely disbursement by calender year, i.e. can the projected disbursements for 2022 be produced from the model?

* What is the plan to move the model from prototype to production and its incorporation in to the ERM Data-mart ?

* We would like to internally compare the performance of the model with our existing disbursement modelling techniques, to gauge how much better it is

* The sign-off plan for this model, given that most of the ERM modules to use it, have yet to come on-line


